
# ğŸ“Š pandas-prompt

**Version**: `0.1.0`  
**Language**: Python 3.7+  
**License**: MIT  
**Author**: *Osama Hosameldeen*  
**LLM Backend**: OpenAI-compatible
**Dependencies**: `pandas`, `openai`, `python-dotenv`

---

## ğŸš€ Overview

`pandas-prompt` is a natural-language interface to the full power of `pandas`.  
It extends `pandas` by adding a `.prompt()` method to any `DataFrame`, letting you write natural language instructions like:

```python
df.prompt("Show the average sales for each department")
```

This is powered by a local or remote LLM (e.g., OpenAI API), which converts the prompt into executable Python code using the DataFrame as `df`.

---

## ğŸ“¦ Installation

1. Clone the repo:

```bash
git clone https://github.com/yourusername/pandas-prompt.git
cd pandas-prompt
```

2. Install locally in development mode:

```bash
pip install -e .
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

Or manually:

```bash
pip install pandas openai python-dotenv
```

---

## ğŸ” Environment Setup

Create a `.env` file in the `pandas_prompt/` directory or project root:

```
OPENAI_API_KEY=your_key_here
```

To use with a custom OpenAI-compatible endpoint (e.g., Vocareum):

```python
self.client = OpenAI(
    base_url="https://openai.vocareum.com/v1",
    api_key=os.getenv("OPENAI_API_KEY")
)
```

---

## ğŸ§ª Example Usage

```python
import pandas_prompt as pdp

df = pdp.read_csv("examples/Sales.csv")

# Ask a question in natural language
result = df.prompt("Show rows where Sales > 1000")
print(result)
```

ğŸ“Œ The `.prompt()` method prints the generated code and returns the result of execution (if any).

---

## ğŸ§  How It Works

- Sample 10 rows from the DataFrame
- Construct a prompt: *â€œGiven this DataFrame: [...], do: [instruction]â€*
- Send to the OpenAI-compatible API
- Parse and execute the returned Python code in a local sandbox

---

## ğŸ”§ Project Structure

```
pandas-prompt/
â”œâ”€â”€ pandas_prompt/
â”‚   â”œâ”€â”€ __init__.py         â† auto-patches pandas on import
â”‚   â”œâ”€â”€ prompt.py           â† PromptEngine + .prompt() logic
â”‚   â”œâ”€â”€ patch.py            â† (optional) manual patch logic
â”‚   â”œâ”€â”€ .env                â† stores your API key
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ demo.py             â† sample usage
â”‚   â””â”€â”€ Sales.csv           â† sample dataset
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ README.md
```

---

## ğŸ“Œ Limitations

- Generated code is executed using `exec()` â€” avoid unsafe prompts
- Only supports `df.prompt(...)` (multi-turn not yet implemented)
- LLM quality depends on prompt and model used

---

## âœ… Planned Features

- âœ… Basic natural language prompt support
- ğŸ”„ Offline support (e.g., Mistral with `llama-cpp`)
- ğŸ“Š `.prompt_plot()` for visualization tasks
- ğŸ§  Multi-turn `.chat()` mode with memory
- ğŸ“ PyPI packaging + GitHub Actions

---

## ğŸ¤ Contributing

Pull requests and issue reports are welcome!  
To contribute:

```bash
git checkout -b my-feature
# make changes
git commit -am "Add new feature"
git push origin my-feature
```

---

## ğŸ“œ License

This project is licensed under the MIT License â€” see the `LICENSE` file for details.
